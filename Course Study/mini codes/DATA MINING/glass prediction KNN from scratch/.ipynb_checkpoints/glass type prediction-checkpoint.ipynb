{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "   1. Id number: 1 to 214\n",
    "   2. RI: refractive index\n",
    "   3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "   4. Mg: Magnesium\n",
    "   5. Al: Aluminum\n",
    "   6. Si: Silicon\n",
    "   7. K: Potassium\n",
    "   8. Ca: Calcium\n",
    "   9. Ba: Barium\n",
    "   10. Fe: Iron\n",
    "   11. Type of glass: (class attribute)\n",
    "   \n",
    "      - 1 building_windows_float_processed\n",
    "      - 2 building_windows_non_float_processed\n",
    "      - 3 vehicle_windows_float_processed\n",
    "      - 4 vehicle_windows_non_float_processed (none in this database)\n",
    "      - 5 containers\n",
    "      - 6 tableware\n",
    "      - 7 headlamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(arr,test):\n",
    "    arr1=[]\n",
    "    for i in arr:\n",
    "        calc=0\n",
    "        for k in range (1,10):\n",
    "            calc+=pow((i[k]-test[k]),2)\n",
    "        arr1+=[[calc,i[10]]]\n",
    "    return arr1    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNcalc(arr,n):\n",
    "    arr1=[9999 for i in range(0,n)]\n",
    "    arr2=[9999 for i in range(0,n)]\n",
    "    for i in arr:\n",
    "        if (i[0]<max(arr1)):\n",
    "            for j in range(0,n):\n",
    "                if(max(arr1)==arr1[j]):\n",
    "                    arr1[j]=i[0]\n",
    "                    arr2[j]=i[1]\n",
    "                    break\n",
    "    return arr1,arr2                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuraccy(arr,n):\n",
    "    count=0\n",
    "    for i  in  arr:\n",
    "        if i==n:\n",
    "            count+=1\n",
    "    return count*100/len(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    train=[]\n",
    "    test=[]\n",
    "    for i in range(0,len(data)):\n",
    "        if(i%15==0):\n",
    "            test+=[data[i]]\n",
    "        else:\n",
    "            train+=[data[i]]\n",
    "    return train,test        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(a):\n",
    "    arr=[0 for i in range(0,8)]\n",
    "    for i in a:\n",
    "        arr[int(i)]+=1\n",
    "    flag=max(arr)\n",
    "    for i in range(0,8):\n",
    "        if(arr[i]==flag):\n",
    "            return(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(test,train,n):\n",
    "    arr=[]\n",
    "    error=0\n",
    "    for i in test:\n",
    "        print(i)\n",
    "        z=calc(train,i)\n",
    "        arr1,arr2=KNNcalc(z,n)\n",
    "        acc=accuraccy(arr2,i[10])\n",
    "        arr+=[acc]\n",
    "        print(\"actual value: \"+str(i[10])+\"  predicted values: \"+str(arr2))\n",
    "        print(\"accuraccy :\"+str(acc)+\"\\n\\n\")\n",
    "        if(pred(arr2)!=i[10]):\n",
    "            error+=1\n",
    "    print(\"total accuraccy\"+str(sum(arr)/15))\n",
    "    \n",
    "    print(\"total error\"+str(error*100/15))\n",
    "    return([sum(arr)/15,error*100/15])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 5, 3]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=[[1,2],[3,5],[8,4],[7,3],[2,5]]\n",
    "arr1,arr2=KNNcalc(arr,4)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Sid\\\\Desktop\\\\python files\\\\glass prediction KNN from scratch\\\\glass.csv\")\n",
    "data=dataset.values.tolist()\n",
    "train,test=split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.51743</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.14</td>\n",
       "      <td>73.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.51756</td>\n",
       "      <td>13.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.51918</td>\n",
       "      <td>14.04</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.51571</td>\n",
       "      <td>12.72</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.56</td>\n",
       "      <td>73.20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.51763</td>\n",
       "      <td>12.80</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.27</td>\n",
       "      <td>73.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.51589</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.40</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.51748</td>\n",
       "      <td>12.86</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.27</td>\n",
       "      <td>73.21</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.51763</td>\n",
       "      <td>12.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.31</td>\n",
       "      <td>73.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.23</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.51784</td>\n",
       "      <td>12.68</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1.16</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.52196</td>\n",
       "      <td>14.36</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.51911</td>\n",
       "      <td>13.90</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.18</td>\n",
       "      <td>72.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.51735</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.69</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.51750</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.49</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.51736</td>\n",
       "      <td>12.78</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.51751</td>\n",
       "      <td>12.81</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.35</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.51720</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>72.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.51764</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.21</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1.51793</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1.51721</td>\n",
       "      <td>12.87</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.33</td>\n",
       "      <td>73.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1.51768</td>\n",
       "      <td>12.56</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.43</td>\n",
       "      <td>73.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1.51784</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.28</td>\n",
       "      <td>72.86</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>1.51131</td>\n",
       "      <td>13.69</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.81</td>\n",
       "      <td>72.81</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>1.51838</td>\n",
       "      <td>14.32</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.22</td>\n",
       "      <td>71.25</td>\n",
       "      <td>1.46</td>\n",
       "      <td>5.79</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>188</td>\n",
       "      <td>1.52315</td>\n",
       "      <td>13.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.23</td>\n",
       "      <td>72.38</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>1.52247</td>\n",
       "      <td>14.86</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.06</td>\n",
       "      <td>70.26</td>\n",
       "      <td>0.76</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>1.52365</td>\n",
       "      <td>15.79</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.31</td>\n",
       "      <td>70.43</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>13.88</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.79</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>1.51602</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>73.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>1.51719</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.53</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.08</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>1.51683</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>73.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.52</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>1.51545</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>73.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.07</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>1.51556</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.54</td>\n",
       "      <td>73.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.41</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>1.51727</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>1.51531</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.66</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>1.51609</td>\n",
       "      <td>15.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.51</td>\n",
       "      <td>73.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>1.51508</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>73.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.34</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>1.51653</td>\n",
       "      <td>11.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>75.18</td>\n",
       "      <td>2.70</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>1.51514</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>73.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>1.51658</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>1.51617</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>206</td>\n",
       "      <td>1.51732</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>207</td>\n",
       "      <td>1.51645</td>\n",
       "      <td>14.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>208</td>\n",
       "      <td>1.51831</td>\n",
       "      <td>14.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>72.86</td>\n",
       "      <td>1.41</td>\n",
       "      <td>6.47</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>1.51640</td>\n",
       "      <td>14.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>72.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     series        A      B     C     D      E     F     G     H     I  RESULT\n",
       "0         1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.00       1\n",
       "1         2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00       1\n",
       "2         3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00       1\n",
       "3         4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00       1\n",
       "4         5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00       1\n",
       "5         6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26       1\n",
       "6         7  1.51743  13.30  3.60  1.14  73.09  0.58  8.17  0.00  0.00       1\n",
       "7         8  1.51756  13.15  3.61  1.05  73.24  0.57  8.24  0.00  0.00       1\n",
       "8         9  1.51918  14.04  3.58  1.37  72.08  0.56  8.30  0.00  0.00       1\n",
       "9        10  1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.00  0.11       1\n",
       "10       11  1.51571  12.72  3.46  1.56  73.20  0.67  8.09  0.00  0.24       1\n",
       "11       12  1.51763  12.80  3.66  1.27  73.01  0.60  8.56  0.00  0.00       1\n",
       "12       13  1.51589  12.88  3.43  1.40  73.28  0.69  8.05  0.00  0.24       1\n",
       "13       14  1.51748  12.86  3.56  1.27  73.21  0.54  8.38  0.00  0.17       1\n",
       "14       15  1.51763  12.61  3.59  1.31  73.29  0.58  8.50  0.00  0.00       1\n",
       "15       16  1.51761  12.81  3.54  1.23  73.24  0.58  8.39  0.00  0.00       1\n",
       "16       17  1.51784  12.68  3.67  1.16  73.11  0.61  8.70  0.00  0.00       1\n",
       "17       18  1.52196  14.36  3.85  0.89  71.36  0.15  9.15  0.00  0.00       1\n",
       "18       19  1.51911  13.90  3.73  1.18  72.12  0.06  8.89  0.00  0.00       1\n",
       "19       20  1.51735  13.02  3.54  1.69  72.73  0.54  8.44  0.00  0.07       1\n",
       "20       21  1.51750  12.82  3.55  1.49  72.75  0.54  8.52  0.00  0.19       1\n",
       "21       22  1.51966  14.77  3.75  0.29  72.02  0.03  9.00  0.00  0.00       1\n",
       "22       23  1.51736  12.78  3.62  1.29  72.79  0.59  8.70  0.00  0.00       1\n",
       "23       24  1.51751  12.81  3.57  1.35  73.02  0.62  8.59  0.00  0.00       1\n",
       "24       25  1.51720  13.38  3.50  1.15  72.85  0.50  8.43  0.00  0.00       1\n",
       "25       26  1.51764  12.98  3.54  1.21  73.00  0.65  8.53  0.00  0.00       1\n",
       "26       27  1.51793  13.21  3.48  1.41  72.64  0.59  8.43  0.00  0.00       1\n",
       "27       28  1.51721  12.87  3.48  1.33  73.04  0.56  8.43  0.00  0.00       1\n",
       "28       29  1.51768  12.56  3.52  1.43  73.15  0.57  8.54  0.00  0.00       1\n",
       "29       30  1.51784  13.08  3.49  1.28  72.86  0.60  8.49  0.00  0.00       1\n",
       "..      ...      ...    ...   ...   ...    ...   ...   ...   ...   ...     ...\n",
       "184     185  1.51115  17.38  0.00  0.34  75.41  0.00  6.65  0.00  0.00       6\n",
       "185     186  1.51131  13.69  3.20  1.81  72.81  1.76  5.43  1.19  0.00       7\n",
       "186     187  1.51838  14.32  3.26  2.22  71.25  1.46  5.79  1.63  0.00       7\n",
       "187     188  1.52315  13.44  3.34  1.23  72.38  0.60  8.83  0.00  0.00       7\n",
       "188     189  1.52247  14.86  2.20  2.06  70.26  0.76  9.76  0.00  0.00       7\n",
       "189     190  1.52365  15.79  1.83  1.31  70.43  0.31  8.61  1.68  0.00       7\n",
       "190     191  1.51613  13.88  1.78  1.79  73.10  0.00  8.67  0.76  0.00       7\n",
       "191     192  1.51602  14.85  0.00  2.38  73.28  0.00  8.76  0.64  0.09       7\n",
       "192     193  1.51623  14.20  0.00  2.79  73.46  0.04  9.04  0.40  0.09       7\n",
       "193     194  1.51719  14.75  0.00  2.00  73.02  0.00  8.53  1.59  0.08       7\n",
       "194     195  1.51683  14.56  0.00  1.98  73.29  0.00  8.52  1.57  0.07       7\n",
       "195     196  1.51545  14.14  0.00  2.68  73.39  0.08  9.07  0.61  0.05       7\n",
       "196     197  1.51556  13.87  0.00  2.54  73.23  0.14  9.41  0.81  0.01       7\n",
       "197     198  1.51727  14.70  0.00  2.34  73.28  0.00  8.95  0.66  0.00       7\n",
       "198     199  1.51531  14.38  0.00  2.66  73.10  0.04  9.08  0.64  0.00       7\n",
       "199     200  1.51609  15.01  0.00  2.51  73.05  0.05  8.83  0.53  0.00       7\n",
       "200     201  1.51508  15.15  0.00  2.25  73.50  0.00  8.34  0.63  0.00       7\n",
       "201     202  1.51653  11.95  0.00  1.19  75.18  2.70  8.93  0.00  0.00       7\n",
       "202     203  1.51514  14.85  0.00  2.42  73.72  0.00  8.39  0.56  0.00       7\n",
       "203     204  1.51658  14.80  0.00  1.99  73.11  0.00  8.28  1.71  0.00       7\n",
       "204     205  1.51617  14.95  0.00  2.27  73.30  0.00  8.71  0.67  0.00       7\n",
       "205     206  1.51732  14.95  0.00  1.80  72.99  0.00  8.61  1.55  0.00       7\n",
       "206     207  1.51645  14.94  0.00  1.87  73.11  0.00  8.67  1.38  0.00       7\n",
       "207     208  1.51831  14.39  0.00  1.82  72.86  1.41  6.47  2.88  0.00       7\n",
       "208     209  1.51640  14.37  0.00  2.74  72.85  0.00  9.45  0.54  0.00       7\n",
       "209     210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00       7\n",
       "210     211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00       7\n",
       "211     212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00       7\n",
       "212     213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00       7\n",
       "213     214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00       7\n",
       "\n",
       "[214 rows x 11 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.142857142857146"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=calc(data,[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0])\n",
    "r1,r2=KNNcalc(z,7)\n",
    "accuraccy(r2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [5.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 1.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 7.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy70.0\n",
      "total error20.0\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [2.0, 2.0, 1.0]\n",
      "accuraccy :33.333333333333336\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 3.0, 3.0]\n",
      "accuraccy :33.333333333333336\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 3.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [3.0, 2.0, 2.0]\n",
      "accuraccy :66.66666666666667\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 5.0]\n",
      "accuraccy :66.66666666666667\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 1.0, 2.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 5.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 7.0, 7.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy66.66666666666667\n",
      "total error33.333333333333336\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 3.0, 1.0]\n",
      "accuraccy :25.0\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 3.0, 3.0, 3.0]\n",
      "accuraccy :25.0\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 3.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 5.0, 5.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :75.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 5.0, 5.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [2.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy65.0\n",
      "total error26.666666666666668\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 1.0, 1.0, 2.0]\n",
      "accuraccy :60.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 1.0, 1.0, 3.0, 3.0]\n",
      "accuraccy :40.0\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 1.0, 1.0, 3.0]\n",
      "accuraccy :40.0\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [3.0, 1.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :40.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 5.0, 5.0]\n",
      "accuraccy :60.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :80.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :80.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 2.0, 2.0, 1.0, 1.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 5.0, 5.0, 5.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 7.0, 2.0, 2.0, 7.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy66.66666666666667\n",
      "total error33.333333333333336\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [2.0, 1.0, 2.0, 2.0, 1.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 7.0, 3.0, 3.0, 3.0]\n",
      "accuraccy :33.333333333333336\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 1.0, 3.0, 3.0, 3.0, 1.0]\n",
      "accuraccy :33.333333333333336\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 1.0, 3.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 5.0, 2.0, 5.0, 2.0, 2.0]\n",
      "accuraccy :66.66666666666667\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :66.66666666666667\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :83.33333333333333\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 1.0, 2.0, 2.0, 3.0, 1.0]\n",
      "accuraccy :16.666666666666668\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [2.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n",
      "accuraccy :83.33333333333333\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [2.0, 7.0, 7.0, 7.0, 2.0, 2.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy65.55555555555556\n",
      "total error26.666666666666668\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :57.142857142857146\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 7.0]\n",
      "accuraccy :28.571428571428573\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0]\n",
      "accuraccy :28.571428571428573\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0]\n",
      "accuraccy :57.142857142857146\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :57.142857142857146\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :57.142857142857146\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :85.71428571428571\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :14.285714285714286\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 2.0, 5.0, 5.0, 2.0, 5.0]\n",
      "accuraccy :71.42857142857143\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 7.0, 7.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy63.80952380952381\n",
      "total error26.666666666666668\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0]\n",
      "accuraccy :62.5\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 7.0]\n",
      "accuraccy :37.5\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0]\n",
      "accuraccy :37.5\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :62.5\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 5.0, 5.0, 2.0, 5.0, 2.0, 5.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :75.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :12.5\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 2.0, 2.0, 5.0, 5.0, 5.0, 5.0]\n",
      "accuraccy :75.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 1.0, 2.0, 7.0, 2.0, 2.0, 2.0, 7.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy64.16666666666667\n",
      "total error20.0\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0]\n",
      "accuraccy :55.55555555555556\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 3.0, 7.0, 1.0, 2.0, 3.0, 3.0]\n",
      "accuraccy :44.44444444444444\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 7.0, 3.0]\n",
      "accuraccy :33.333333333333336\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0]\n",
      "accuraccy :55.55555555555556\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [5.0, 5.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0, 2.0]\n",
      "accuraccy :44.44444444444444\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0]\n",
      "accuraccy :55.55555555555556\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0]\n",
      "accuraccy :77.77777777777777\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :11.11111111111111\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [2.0, 5.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0]\n",
      "accuraccy :66.66666666666667\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 1.0, 7.0, 2.0, 2.0, 2.0, 2.0, 7.0, 2.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy62.96296296296295\n",
      "total error26.666666666666668\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 7.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0]\n",
      "accuraccy :40.0\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 7.0]\n",
      "accuraccy :40.0\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 7.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 2.0, 2.0, 5.0, 2.0]\n",
      "accuraccy :40.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :60.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :80.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :10.0\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :60.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 1.0, 2.0, 7.0, 2.0, 2.0, 2.0, 6.0, 2.0, 7.0]\n",
      "accuraccy :10.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy62.666666666666664\n",
      "total error20.0\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0]\n",
      "accuraccy :54.54545454545455\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0]\n",
      "accuraccy :90.9090909090909\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 7.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :45.45454545454545\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 7.0, 3.0, 3.0, 2.0, 1.0]\n",
      "accuraccy :36.36363636363637\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :90.9090909090909\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 7.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :54.54545454545455\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 5.0, 5.0, 2.0, 5.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0]\n",
      "accuraccy :45.45454545454545\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0]\n",
      "accuraccy :63.63636363636363\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :81.81818181818181\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :18.181818181818183\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [2.0, 1.0, 5.0, 5.0, 2.0, 5.0, 2.0, 5.0, 2.0, 5.0, 5.0]\n",
      "accuraccy :54.54545454545455\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 1.0, 2.0, 7.0, 2.0, 6.0, 2.0, 7.0, 2.0, 2.0, 7.0]\n",
      "accuraccy :9.090909090909092\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy63.03030303030302\n",
      "total error26.666666666666668\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :91.66666666666667\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 1.0, 3.0, 3.0, 1.0, 7.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0]\n",
      "accuraccy :41.666666666666664\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 3.0, 3.0, 7.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0]\n",
      "accuraccy :33.333333333333336\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :91.66666666666667\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [3.0, 2.0, 2.0, 7.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :58.333333333333336\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [5.0, 2.0, 5.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 5.0, 2.0, 5.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :66.66666666666667\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :83.33333333333333\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :16.666666666666668\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 2.0, 2.0, 5.0, 5.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 1.0, 2.0, 6.0, 2.0, 7.0, 2.0, 2.0, 7.0, 2.0, 7.0, 7.0]\n",
      "accuraccy :8.333333333333334\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy62.777777777777786\n",
      "total error20.0\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :53.84615384615385\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :92.3076923076923\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 7.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :38.46153846153846\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 7.0, 3.0, 3.0, 3.0, 3.0, 3.0]\n",
      "accuraccy :30.76923076923077\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :84.61538461538461\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 7.0, 3.0, 1.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :53.84615384615385\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [5.0, 2.0, 5.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 2.0, 5.0, 6.0, 2.0]\n",
      "accuraccy :46.15384615384615\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0]\n",
      "accuraccy :61.53846153846154\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :76.92307692307692\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0]\n",
      "accuraccy :15.384615384615385\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [2.0, 2.0, 5.0, 5.0, 5.0, 5.0, 1.0, 2.0, 2.0, 5.0, 5.0, 5.0, 2.0]\n",
      "accuraccy :53.84615384615385\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [7.0, 1.0, 2.0, 7.0, 7.0, 6.0, 2.0, 7.0, 2.0, 7.0, 2.0, 7.0, 2.0]\n",
      "accuraccy :7.6923076923076925\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy61.02564102564102\n",
      "total error20.0\n",
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :92.85714285714286\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 7.0, 3.0, 1.0, 2.0, 1.0]\n",
      "accuraccy :42.857142857142854\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 2.0, 3.0, 3.0, 7.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :35.714285714285715\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0]\n",
      "accuraccy :78.57142857142857\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 7.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [5.0, 6.0, 2.0, 5.0, 5.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 5.0, 5.0]\n",
      "accuraccy :42.857142857142854\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0]\n",
      "accuraccy :64.28571428571429\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :71.42857142857143\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0]\n",
      "accuraccy :14.285714285714286\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [1.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 2.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n",
      "accuraccy :57.142857142857146\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [1.0, 1.0, 2.0, 7.0, 7.0, 7.0, 2.0, 2.0, 6.0, 7.0, 2.0, 7.0, 7.0, 2.0]\n",
      "accuraccy :7.142857142857143\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy60.476190476190474\n",
      "total error26.666666666666668\n"
     ]
    }
   ],
   "source": [
    "bestKNN=[]\n",
    "for i in range(2,15):\n",
    "    bestKNN+=[[i]+acc(test,train,i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.52101, 13.64, 4.49, 1.1, 71.78, 0.06, 8.75, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[16.0, 1.5176100000000001, 12.81, 3.54, 1.23, 73.24, 0.58, 8.39, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[31.0, 1.51768, 12.65, 3.56, 1.3, 73.08, 0.61, 8.69, 0.0, 0.14, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 1.0, 1.0, 1.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[46.0, 1.5190000000000001, 13.49, 3.48, 1.35, 71.95, 0.55, 9.0, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [3.0, 3.0, 3.0, 1.0]\n",
      "accuraccy :25.0\n",
      "\n",
      "\n",
      "[61.0, 1.51905, 13.6, 3.62, 1.11, 72.64, 0.14, 8.76, 0.0, 0.0, 1.0]\n",
      "actual value: 1.0  predicted values: [1.0, 3.0, 3.0, 3.0]\n",
      "accuraccy :25.0\n",
      "\n",
      "\n",
      "[76.0, 1.5159, 13.02, 3.58, 1.51, 73.12, 0.69, 7.96, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[91.0, 1.51841, 12.93, 3.74, 1.11, 72.28, 0.64, 8.96, 0.0, 0.22, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 3.0, 1.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[106.0, 1.52475, 11.45, 0.0, 1.88, 72.19, 0.81, 13.24, 0.0, 0.34, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 5.0, 5.0]\n",
      "accuraccy :50.0\n",
      "\n",
      "\n",
      "[121.0, 1.51844, 13.25, 3.76, 1.32, 72.4, 0.58, 8.42, 0.0, 0.0, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 1.0, 2.0]\n",
      "accuraccy :75.0\n",
      "\n",
      "\n",
      "[136.0, 1.51789, 13.19, 3.9, 1.3, 72.33, 0.55, 8.44, 0.0, 0.28, 2.0]\n",
      "actual value: 2.0  predicted values: [2.0, 2.0, 2.0, 2.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[151.0, 1.51665, 13.14, 3.45, 1.76, 72.48, 0.6, 8.38, 0.0, 0.17, 3.0]\n",
      "actual value: 3.0  predicted values: [2.0, 2.0, 2.0, 1.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[166.0, 1.5217100000000001, 11.56, 1.88, 1.56, 72.86, 0.47, 11.41, 0.0, 0.0, 5.0]\n",
      "actual value: 5.0  predicted values: [5.0, 5.0, 5.0, 5.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[181.0, 1.51299, 14.4, 1.74, 1.54, 74.55, 0.0, 7.59, 0.0, 0.0, 6.0]\n",
      "actual value: 6.0  predicted values: [2.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :0.0\n",
      "\n",
      "\n",
      "[196.0, 1.51545, 14.14, 0.0, 2.68, 73.39, 0.08, 9.07, 0.61, 0.05, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "[211.0, 1.51685, 14.92, 0.0, 1.99, 73.06, 0.0, 8.4, 1.59, 0.0, 7.0]\n",
      "actual value: 7.0  predicted values: [7.0, 7.0, 7.0, 7.0]\n",
      "accuraccy :100.0\n",
      "\n",
      "\n",
      "total accuraccy65.0\n",
      "total error26.666666666666668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[65.0, 26.666666666666668]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(test,train,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 70.0, 20.0],\n",
       " [3, 66.66666666666667, 33.333333333333336],\n",
       " [4, 65.0, 26.666666666666668],\n",
       " [5, 66.66666666666667, 33.333333333333336],\n",
       " [6, 65.55555555555556, 26.666666666666668],\n",
       " [7, 63.80952380952381, 26.666666666666668],\n",
       " [8, 64.16666666666667, 20.0],\n",
       " [9, 62.96296296296295, 26.666666666666668],\n",
       " [10, 62.666666666666664, 20.0],\n",
       " [11, 63.03030303030302, 26.666666666666668],\n",
       " [12, 62.777777777777786, 20.0],\n",
       " [13, 61.02564102564102, 20.0],\n",
       " [14, 60.476190476190474, 26.666666666666668]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the best result is found using 8 neighbours having 64% acc match and 20% error\n",
    "bestKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=calc(data,[176.0, 1.52119, 12.97, 0.33, 1.51, 73.39, 0.13, 11.27, 0.0, 0.28, 5.0])\n",
    "arr1,arr2=KNNcalc(z,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 2.0, 6.0, 5.0, 5.0, 2.0, 5.0, 5.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
